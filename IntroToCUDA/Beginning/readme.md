# Why CUDA?
- Simply put, NVIDIA GPUs are the fastest available for AI/ML: most modern deep learning neural nets are perfect for parallelization, which these GPUs specialize in.

# Goals of this learning: 
1. Understand how Nvidia GPUs work on a deeper level: being able to look at a problem and leverage the hardware to code custom kernels for it
2. Understand where CUDA is used/how it is written today on the cutting edge (triton? pytorch? tensorflow?)/ where can I take this further?